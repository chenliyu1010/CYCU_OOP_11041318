import sys
import requests
import html
import pandas as pd
from bs4 import BeautifulSoup
import os
from concurrent.futures import ThreadPoolExecutor

# è¨­å®šè¼¸å‡ºç·¨ç¢¼ç‚º UTF-8ï¼Œé¿å… UnicodeEncodeError
sys.stdout.reconfigure(encoding='utf-8')

# è¨­å®š User-Agent é¿å…è¢«å°é–
HEADERS = {"User-Agent": "Mozilla/5.0"}

def get_stop_info(stop_link: str):
    """ä¸‹è¼‰ä¸¦å„²å­˜æŒ‡å®šç«™é»çš„ HTML é é¢"""
    url = f'https://pda5284.gov.taipei/MQS/{stop_link}'
    
    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        response.raise_for_status()

        # è®€å–ç«™é» ID
        stop_id = stop_link.split("=")[1]

        with open(f"bus_stop_{stop_id}.html", "w", encoding="utf-8") as file:
            file.write(response.text)

        print(f"âœ… ä¸‹è¼‰å®Œæˆï¼šbus_stop_{stop_id}.html")

    except requests.exceptions.RequestException as e:
        print(f"âŒ ä¸‹è¼‰å¤±æ•— {stop_link}: {e}")

def get_bus_route(rid: str):
    """æ ¹æ“šå…¬è»Šè·¯ç·š ID å–å¾—å»ç¨‹èˆ‡å›ç¨‹çš„ç«™é»è³‡è¨Šï¼Œå›å‚³ DataFrame"""
    url = f'https://pda5284.gov.taipei/MQS/route.jsp?rid={rid}'

    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        response.raise_for_status()
        
        # å„²å­˜ HTML æª”æ¡ˆ
        with open(f"bus_route_{rid}.html", "w", encoding="utf-8") as file:
            file.write(response.text)

        # ä½¿ç”¨ BeautifulSoup è§£æ HTML
        soup = BeautifulSoup(response.text, "html.parser")

        # åˆå§‹åŒ–å…©å€‹ DataFrame
        go_stops = []
        return_stops = []

        # æ‰¾å‡ºæ‰€æœ‰å…¬è»Šç«™é»è¡¨æ ¼
        tables = soup.find_all("table")

        for table in tables:
            # å»ç¨‹ç«™é» (ttego1, ttego2)
            for tr in table.find_all("tr", class_=["ttego1", "ttego2"]):
                td = tr.find("td")
                if td:
                    stop_name = html.unescape(td.text.strip())
                    stop_link = td.find("a")["href"] if td.find("a") else None
                    go_stops.append({"stop_name": stop_name, "stop_link": stop_link})

            # å›ç¨‹ç«™é» (tteback1, tteback2)
            for tr in table.find_all("tr", class_=["tteback1", "tteback2"]):
                td = tr.find("td")
                if td:
                    stop_name = html.unescape(td.text.strip())
                    stop_link = td.find("a")["href"] if td.find("a") else None
                    return_stops.append({"stop_name": stop_name, "stop_link": stop_link})

        # è½‰æ›ç‚º DataFrame
        df_go = pd.DataFrame(go_stops)
        df_return = pd.DataFrame(return_stops)

        # å„²å­˜ CSV æ–¹ä¾¿å¾ŒçºŒåˆ†æ
        df_go.to_csv(f"å»ç¨‹ç«™é»_{rid}.csv", index=False, encoding="utf-8")
        df_return.to_csv(f"å›ç¨‹ç«™é»_{rid}.csv", index=False, encoding="utf-8")

        return df_go, df_return

    except requests.exceptions.RequestException as e:
        raise ValueError(f"âŒ ç„¡æ³•ä¸‹è¼‰ç¶²é : {e}")

def download_all_stops(df: pd.DataFrame):
    """å¤šç·šç¨‹ä¸‹è¼‰æ‰€æœ‰ç«™é»çš„ HTML é é¢"""
    os.makedirs("stations_html", exist_ok=True)

    with ThreadPoolExecutor(max_workers=5) as executor:
        for _, row in df.iterrows():
            if row["stop_link"]:
                executor.submit(get_stop_info, row["stop_link"])

# æ¸¬è©¦å‡½æ•¸
if __name__ == "__main__":
    rid = "10417"  # æ¸¬è©¦å…¬è»Šè·¯ç·š ID

    try:
        df_go, df_return = get_bus_route(rid)

        print("\nğŸš å»ç¨‹ç«™é» DataFrame:")
        print(df_go)

        print("\nğŸš å›ç¨‹ç«™é» DataFrame:")
        print(df_return)

        # ä¸‹è¼‰æ‰€æœ‰ç«™é»çš„ HTML é é¢
        print("\nğŸš€ é–‹å§‹ä¸‹è¼‰æ‰€æœ‰ç«™é»è©³ç´°è³‡è¨Š...")
        download_all_stops(pd.concat([df_go, df_return]))

    except ValueError as e:
        print(f"Error: {e}")
